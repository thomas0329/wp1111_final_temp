{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40631439",
   "metadata": {},
   "source": [
    "# Run with python 3.10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4467ff9-d462-4a74-ab18-b853a0ad6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed61597-2cf5-47f9-a113-b9f1de59eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb69450-3385-40f9-a9d2-dcfdec943537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 11:25:45.342380: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_models/model-33999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:10<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import network\n",
    "import guided_filter\n",
    "from tqdm import tqdm\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "def resize_crop(image):\n",
    "    h, w, c = np.shape(image)\n",
    "    if min(h, w) > 720:\n",
    "        if h > w:\n",
    "            h, w = int(720*h/w), 720\n",
    "        else:\n",
    "            h, w = 720, int(720*w/h)\n",
    "    image = cv2.resize(image, (w, h),\n",
    "                       interpolation=cv2.INTER_AREA)\n",
    "    h, w = (h//8)*8, (w//8)*8\n",
    "    image = image[:h, :w, :]\n",
    "    return image\n",
    "    \n",
    "\n",
    "def cartoonize(load_folder, save_folder, model_path):\n",
    "    input_photo = tf.placeholder(tf.float32, [1, None, None, 3])\n",
    "    network_out = network.unet_generator(input_photo)\n",
    "    final_out = guided_filter.guided_filter(input_photo, network_out, r=1, eps=5e-3)\n",
    "\n",
    "    all_vars = tf.trainable_variables()\n",
    "    gene_vars = [var for var in all_vars if 'generator' in var.name]\n",
    "    saver = tf.train.Saver(var_list=gene_vars)\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "    name_list = os.listdir(load_folder)\n",
    "    for name in tqdm(name_list):\n",
    "        try:\n",
    "            load_path = os.path.join(load_folder, name)\n",
    "            save_path = os.path.join(save_folder, name)\n",
    "            image = cv2.imread(load_path)\n",
    "            image = resize_crop(image)\n",
    "            batch_image = image.astype(np.float32)/127.5 - 1\n",
    "            batch_image = np.expand_dims(batch_image, axis=0)\n",
    "            output = sess.run(final_out, feed_dict={input_photo: batch_image})\n",
    "            output = (np.squeeze(output)+1)*127.5\n",
    "            output = np.clip(output, 0, 255).astype(np.uint8)\n",
    "            cv2.imwrite(save_path, output)\n",
    "        except:\n",
    "            print('cartoonize {} failed'.format(load_path))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = 'saved_models'\n",
    "    load_folder = 'test_images'\n",
    "    save_folder = 'cartoonized_images'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)\n",
    "    cartoonize(load_folder, save_folder, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "62f0de500e91648e2f1c8ecd59ca95f97588cc062e27f09a44618e0428f97b74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
